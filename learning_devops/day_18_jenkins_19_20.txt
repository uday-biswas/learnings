//learning ci/cd with jenkins and github
-> setting up jenkins 
connect with your aws or azure virtual machine, then

------------------------------------------------
//method 1- normal downloading jenkins
firstly download java using the commands:
sudo apt install openjdk-17-jdk

-> then download jenkins using the commands:
curl -fsSL https://pkg.jenkins.io/debian/jenkins.io-2023.key | sudo tee \
  /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
  https://pkg.jenkins.io/debian binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins

-> then start jenkins using the command: sudo systemctl start jenkins
-> then check the status of jenkins using the command: sudo systemctl status jenkins

//method 2- using docker
firstly install docker using the command: sudo apt install docker.io
then grant jenkins user permission to run docker deamon: sudo usermod -aG docker jenkins
then restart the docker using the command: sudo systemctl restart docker

-> then run jenkins image using the command: 
sudo docker run -d -p 8080:8080 -p 50000:50000 -d \
-v /var/run/docker.sock:/var/run/docker.sock \
-v $(which docker):/usr/bin/docker \
-v jenkins_home:/var/jenkins_home jenkins/jenkins:lts

in the above docker.sock and docker binary of host is used in the container to run docker commands in the container, 
which is called docker in docker method.

==> now when we want to start jenkins, we can use the command:
docker start <container-id>

-> then go inside the jenkins container using the command:
docker exec -u 0 -it <container-id> /bin/bash
-> then change the permission of the docker.sock using the command:
chmod 666 /var/run/docker.sock   or  chown jenkins:docker /var/run/docker.sock
-> then check whether the docker is working in the container using the command:
docker ps
------------------------------------------------

now allow jenkins to run on port 8080 in aws by adding a new inbound rule in security group
by choosing custom , tcp, port 8080, source anywhere.
then open the jenkins dashboard with the url http://<public-ip>:8080 (public-ip of aws instance) in browser and 
login with the password generated in the terminal using the command:
for method 1 - sudo cat /var/lib/jenkins/secrets/initialAdminPassword  
for method 2 - sudo docker exec -it <container-id> cat /var/jenkins_home/secrets/initialAdminPassword

-> then install the suggested plugins and create a new admin user
we can download required plugins from the manage jenkins -> manage plugins -> available -> search for the plugin 
or we can download directly on the jenkins server, this method is very 
flexible as we can write commands directly to the shell of the job , instead of using the plugins.

for downloading the required plugins directly on the jenkins server:
-> go inside the jenkins server using the command: sudo docker exec -u 0 -it <container-id> /bin/bash
-> now for example to download the nodejs plugin, run the command:
apt update
curl -sL https://deb.nodesource.com/setup_20.x -o nodesource_setup.sh
bash nodesource_setup.sh
apt-get install nodejs -y
node -v
npm -v

//creating a new job in jenkins for automating the build process
click on new item -> give a name -> select freestyle -> ok
-> in the source code management section, select git and give the repository url and credentials
-> in the build steps section, select execute shell and write the commands to be executed
for example: npm install
             npm run build
             npm test
-> save the job and click on build now to run the job

==> example job for a nodejs project from github with dockerfile:
-> click on new item -> give a name -> select freestyle -> ok
-> in the source code management section, select git and give the repository url and github credentials
-> in the build environment section, select use secret text(s) or file(s) and create the dockerhub credentials and declare username and password variables
-> in the build steps section, select execute shell and write the commands to be executed:
docker build -t udaybiswas944/skillquake:latest .
docker images 
echo $DOCKERHUB_PASSWORD | docker login -u $DOCKERHUB_USERNAME --password-stdin
docker push udaybiswas944/skillquake

-> save the job and click on build now to run the job

=> professionally , we should use jenkins pipeline for automating the build process, as it is more flexible and powerful
-> click on new item -> give a name -> select pipeline -> ok 
-> in the pipeline section, select pipeline script from scm and give the repository url and credentials, and Jenkinsfile path
-> save the job and click on build now to run the job

the example Jenkinsfile for a nodejs project from github with dockerfile:
pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo "building the docker image"
                withCredentials([usernamePassword(credentialsId: 'dockerhub_credentials', usernameVariable: 'DOCKERHUB_USERNAME', passwordVariable: 'DOCKERHUB_PASSWORD')]) {
                    sh 'docker build -t udaybiswas944/skillquake:latest .'
                    sh "echo $DOCKERHUB_PASSWORD | docker login -u $DOCKERHUB_USERNAME --password-stdin"
                    sh 'docker push udaybiswas944/skillquake:latest'
                }
            }
        }
        stage('Test') {
            steps {
                echo 'Testing the app'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying the app'
            }
        }
    }
}

=> using the multibranch pipeline for automating the build process for multiple branches
-> click on new item -> give a name -> select multibranch pipeline -> ok
-> in the branch sources section, select github and give the repository url and credentials and the branch source
-> in the build configuration section, select the jenkinsfile path
-> save the job and click on build now to run the job 

=> example Jenkinsfile for a nodejs project from github with dockerfile for multibranch pipeline:
pipeline {
    agent any
    stages {
        stage('Build') {
            when {
                expression {
                  BRANCH_NAME == 'master'
                }
            }
            steps {
                echo "building the docker image"
                withCredentials([usernamePassword(credentialsId: 'dockerhub_credentials', usernameVariable: 'DOCKERHUB_USERNAME', passwordVariable: 'DOCKERHUB_PASSWORD')]) {
                    sh 'docker build -t udaybiswas944/skillquake:latest .'
                    sh "echo $DOCKERHUB_PASSWORD | docker login -u $DOCKERHUB_USERNAME --password-stdin"
                    sh 'docker push udaybiswas944/skillquake:latest'
                }
            }
        }
        stage('Test') {
            steps {
                echo 'Testing the app'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying the app'
            }
        }
    }
}
//the above Jenkinsfile will create pipelines for all the branches but
  only build the docker image for the master branch.
  test and deploy stages will be executed for all the branches in their respective pipelines.

==> using the github webhook for automating the build process:
-> go to the github repository -> settings -> webhooks -> add webhook
-> give the payload url as http://<public-ip>:8080 and content type as application/json
-> select the individual events and click on add webhook
-> now whenever a push event occurs in the repository, the webhook will be triggered and the jenkins job will be executed



//using github actions for ci/cd    
-> create a new repo in github
-> create a new branch
-> create a new file in the branch
-> create a new folder .github/workflows
-> create a new file in the folder with the name main.yml
-> write the workflow code in the file
-> now on commiting the changes, the workflow will be triggered
-> check the actions tab in the repo

example workflow code for a python project:
name: my first workflow
on: [push]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: set up python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: run tests
      run: |
        python test.py
        
-> example workflow code for a nodejs project:
name: Node.js CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
    build:
        runs-on: ubuntu-latest
    
        strategy:
        matrix:
            node-version: [14.x]
    
        steps:
        - uses: actions/checkout@v2
        - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v2
        with:
            node-version: ${{ matrix.node-version }}
        - run: npm ci
        - run: npm run build --if-present
        - run: npm test
