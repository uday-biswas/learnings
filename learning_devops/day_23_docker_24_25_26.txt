-> container - A container is a standard unit of software that packages 
up code and all its dependencies so the application runs quickly and 
reliably from one computing environment to another. A Docker container 
image is a lightweight, standalone, executable package of software 
that includes everything needed to run an application: code, runtime, 
system tools, system libraries and settings.

-> containers vs virtual machines
both are used to isolate applications and their dependencies, but they
have some key differences:
1. Resource Utilization: Containers share the host operating system kernel, 
making them lighter and faster than VMs. VMs have a full-fledged OS and 
hypervisor, making them more resource-intensive.

2. Portability: Containers are designed to be portable and can run on 
any system with a compatible host operating system. VMs are less portable 
as they need a compatible hypervisor to run.

3. Security: VMs provide a higher level of security as each VM has its 
own operating system and can be isolated from the host and other VMs. 
Containers provide less isolation, as they share the host operating system.

-> why containers are light weight?
Containers are lightweight because they use a technology called containerization, 
which allows them to share the host operating system's kernel and 
libraries, while still providing isolation for the application and 
its dependencies. This results in a smaller footprint compared to 
traditional virtual machines, as the containers do not need to include 
a full operating system. Additionally, Docker containers are designed 
to be minimal, only including what is necessary for the application to 
run, further reducing their size.

-> what is docker?
docker is a platform that provides easy way to containerize our applications
, which means using docker we can build and run our applications in containers,
and also we can push these images to registry such as dockerhub,quay.io etc 
and can pull them from there and run them on any machine.
dockerhub is similar to github, but instead of code we push and pull images.

-> docker architecture
there are three main components in docker architecture: client, daemon and registry.
- client : it is the interface between user and docker daemon, it takes commands from user
    such as build, run, pull etc and sends them to docker daemon.
- daemo(server) : it is the background process that runs on host machine, it is responsible for
    building, running, pulling etc images.
- registry : it is a place where we can push our images, it is similar to github, but
    instead of code we push and pull images. example: dockerhub, quay.io etc.

-> docker server(daemon) has four important components:
   - container runtime: for pulling images and managing container lifecycle
   - volumes : for managing data persistence
   - networks : for managing network connectivity between containers
   - build images: for building images from dockerfile

-> docker lifecycle
There are three important things, 

- docker build -> builds docker images from Dockerfile
- docker run -> runs container from docker images
- docker push -> push the container image to public/private regestries to share the docker images.

-> dockerfile - it is a file that contains instructions to build docker images.
    it is similar to makefile, but instead of building binaries, it builds docker images.
    it contains instructions such as from, run, copy, entrypoint etc.
    example:
    FROM ubuntu:latest
    RUN apt-get update && apt-get install -y python3
    COPY . /app
    ENTRYPOINT ["python3"]
    CMD ["app.py"]

-> docker image - it is a file that contains all the dependencies and binaries required to run
    an application. it is built from dockerfile.

-> docker container - it is a running instance of docker image.

-> installing and running docker on ubuntu

- installing docker
    sudo apt-get update
    sudo apt-get install docker.io -y    //installing docker
    sudo systemctl start docker         //starting docker
    sudo systemctl status docker          //checking status of docker

- enabling non-root user to run docker
    sudo groupadd -f docker            //creating docker group
    sudo usermod -aG docker $USER      //adding current user to docker group
    newgrp docker                      //applying the group changes to the current terminal
  
- running docker
    docker run hello-world             //running hello-world container
    docker run -it ubuntu:latest bash  //running ubuntu container in interactive mode

//lets run a mern stack project in docker 
    git clone https://github.com/uday-biswas/skillQuake-main.git
    cd skillQuake-main
    touch Dockerfile
    vim Dockerfile

    //write the following code in Dockerfile
    # Use an official Node.js runtime as the base image
    FROM node:20

    # Set the working directory in the container
    WORKDIR /app/backend

    # Copy package.json and package-lock.json to the working directory
    COPY backend/package*.json ./

    # Install project dependencies
    RUN npm install

    # Copy the rest of the project files to the working directory
    COPY backend/ .

    # Set the working directory in the container
    WORKDIR /app/frontend

    # Copy package.json and package-lock.json to the working directory
    COPY frontend/package*.json ./

    # Install project dependencies
    RUN npm install

    # Copy the rest of the project files to the working directory
    COPY frontend/ .

    # set the working directory for app
    WORKDIR /app

    # copy package.json and package-lock.json to the working directory
    COPY package*.json ./

    # install project dependencies
    RUN npm install

    # Expose the port the app runs on
    EXPOSE 3000

    #expose the port the backend runs on
    EXPOSE 4000

    # Start the application
    CMD ["npm", "run", "dev"]

    //build docker image from Dockerfile
    docker build -t udaybiswas944/skillquake:latest .

    docker images                        //list all the docker images and check if skillquake image is present
    docker run --env-file backend/.env --env-file frontend/.env -p 3000:3000 -p 4000:4000 -t udaybiswas944/skillquake     //run skillquake container from skillquake image
    docker login                          //login to dockerhub to push skillquake image to dockerhub
    docker push udaybiswas944/skillquake    //push skillquake image to dockerhub

    -> if the dockerfile is modified , then we need to stop the container and remove the image and then build the image again.


//we can use multi stage docker build to reduce the size of images formed
-> here we are building and copying the files in first stage 
   and then copying the built files in second stage
-> content of Dockerfile for multi stage

# Stage 1: Build the application
FROM node:20 AS builder

# Set the working directory for the backend
WORKDIR /app/backend

# Copy package.json and package-lock.json for backend to the working directory
COPY backend/package*.json ./

# Install backend project dependencies
RUN npm install

# Copy the rest of the backend files to the working directory
COPY backend/ .

# Set the working directory for the frontend
WORKDIR /app/frontend

# Copy package.json and package-lock.json for frontend to the working directory
COPY frontend/package*.json ./

# Install frontend project dependencies
RUN npm install

# Copy the rest of the frontend files to the working directory
COPY frontend/ .

# Set the working directory for the application
WORKDIR /app

# Copy the rest of the files to the working directory
COPY package*.json ./

# Install project dependencies
RUN npm install

# Stage 2: Create the production image
FROM node:20

# Set the working directory for the application
WORKDIR /app

# Copy built backend files from the builder stage
COPY --from=builder /app/backend /app/backend

# Copy built frontend files from the builder stage
COPY --from=builder /app/frontend /app/frontend

# Copy built application files from the builder stage
COPY --from=builder /app /app

# Expose the port the app runs on (3000 for frontend, 4000 for backend)
EXPOSE 3000
EXPOSE 4000

# Start the application
CMD ["npm", "run", "dev"]


//extras for docker
docker ps -a            //list all the containers whether running or not
-> if we want to start a container individually, then the command is:
    docker start <container_id>
-> if we want to start all the containers, then the command is:
    docker start $(docker ps -aq)
-> if we want to remove the containers not running individually, then the command is:
    docker rm <container_id>        
-> if we want to remove all the containers not running, then the command is:
    docker container prune
-> if we want to stop the containers running individually, then the command is:
    docker stop <container_id>
-> if we want to stop all the containers running, then the command is:
    docker stop $(docker ps -aq)

docker images            //list all the docker images created   
-> if we want to remove the docker images individually, then the command is:
    docker rmi <image_id>
-> if we want to remove all the docker images, then the command is:
    docker image prune

-> debugging in docker
docker exec -it <container_id> /bin/bash    //it will open the bash terminal of the container
docker logs <container_id>                  //check the logs of the container

